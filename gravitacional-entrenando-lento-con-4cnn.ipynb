{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport os\nfrom sklearn.model_selection import train_test_split\nimport time\n\n#import tensorflow.keras as keras\n#from keras import backend as K\nfrom sklearn.preprocessing import OneHotEncoder\n\n#import tensorflow as tf\nimport random\n\nimport torch\nfrom torch import nn, optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, sampler, random_split, Dataset\nimport math\nfrom IPython.display import display\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analisis","metadata":{}},{"cell_type":"code","source":"totalDir=0\ntotalFiles=0\nfor base, dirs, files in os.walk('../input/g2net-gravitational-wave-detection/train'):\n    #print('Searching in : ',base)\n    for directories in dirs:\n        totalDir += 1\n    for Files in files:\n        totalFiles += 1\n        \nprint('Total number of files',totalFiles,'\\n\\n')\n\n\nlabels = pd.read_csv('../input/g2net-gravitational-wave-detection/training_labels.csv')\nlabels.info()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_complete_path(basedir, file_id): \n    #return os.path.join(basedir, file_id[0], file_id[1], file_id[2], file_id+ '.npy' )\n    return os.path.join(basedir,file_id[0], file_id[1], file_id[2], file_id+ '.npy' )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Revisamos si están balanceadas las clases\nprint(len(labels))#total de observaciones\nlabels.target.sum()# total de clase 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#leer N ejemplos aleatorios\nN=5\n\noptions = random.sample(range(0, 150), N)\n\n\neventos = [labels['id'].iloc[i] for i in options]\ncategorias = [labels['target'].iloc[i]for i in options]\n\nprint(eventos)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_array_list=[]\nfor evento in eventos:\n    path=get_complete_path('../input/g2net-gravitational-wave-detection/train/',evento)\n    data_array = np.load(path)\n    data_array_list.append(data_array)\n    \n'''print(\"\\nData summary:\\n\", data_array)\nprint(\"\\nData shape:\\n\", data_array.shape)\n'''\ndf = pd.DataFrame(data_array).T\n\nfig, axs =f, axs = plt.subplots(N,figsize=(15,5*N)) \nfor i in range(N):\n    for j in range(3):\n        \n        axs[i].plot(data_array_list[i][j])\n        \n\n#df.plot( figsize=(15,4))\n\nprint(\"\\n\\n\\n--------------------------------Las categoría son:\",categorias,'---------------------------\\n\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preparación ","metadata":{}},{"cell_type":"code","source":"\n\nclass Dataset(torch.utils.data.Dataset):\n    'Characterizes a dataset for PyTorch'\n    def __init__(self, list_IDs, labels):\n        'Initialization'\n        self.labels = labels\n        #print(self.labels)\n        self.list_IDs = list_IDs\n        #print(self.list_IDs)\n    def __len__(self):\n        'Denotes the total number of samples'\n        return len(self.list_IDs)\n\n    def __getitem__(self, index):\n        'Generates one sample of data'\n        # Select sample\n        #print(index)\n        ID = self.list_IDs[index]\n        #print('ID',ID)    \n        # Load data and get label\n        path = get_complete_path('../input/g2net-gravitational-wave-detection/train', ID)\n        #print(path)\n        X = torch.from_numpy(np.load(path))\n        #print(X)\n        y = self.labels[index]\n        #print(y)\n\n        return X, y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_trainDL(labels):\n    trainingDS = Dataset(labels['id'], labels['target'])\n    training_generator = DataLoader(trainingDS,batch_size=1024, shuffle=True)\n    return trainingDS , training_generator \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_train_data(path,labels):\n    data_list=[]\n    target_list=[]\n    n=1\n    for base, dirs, files in os.walk(path):\n        for file in files:\n            indir=base[:-5]\n            n+=1\n            file_path = get_complete_path(indir,file)[:-4]\n            array = np.load(file_path)\n            #array = array.transpose()\n            data_list.append(array)\n            a=labels.loc[labels['id'] == file[:-4], 'target'].iloc[0]\n            target_list.append(a)\n    data = np.stack(data_list, axis=0)\n    data_l = np.array(target_list)\n    data_l = data_l.reshape(data_l.shape[0],-1)\n    return data,data_l\n            \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nmsk = np.random.rand(len(labels)) < 0.98\ntrain_data=labels[msk].reset_index()\nval_data=labels[~msk].reset_index()\n#print(len(train_data),len(val_data))\ntrain, train_dl = make_trainDL(train_data)\nval, val_dl = make_trainDL(val_data)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Para probar el DataLoader","metadata":{}},{"cell_type":"code","source":"# Display text and label.\nprint('\\nFirst iteration of data set: ', next(iter(train_dl)), '\\n')# Print how many items are in the data set\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(train.shape,y_labels.shape)\n\ntrainiter = iter(train_dl)\nfeatures, labels = next(trainiter)\nprint(features.shape, labels.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analisis de frecuencias","metadata":{}},{"cell_type":"markdown","source":"from scipy.fft import fft, ifft,fftfreq,rfft,rfftfreq\n\nyf=[]\nyf.append(rfft(train[1][0]))\n#yf.append(rfft(train[1][1]))\n#yf.append(rfft(train[1][2]))\n\n# Number of sample points\nprint(np.abs(yf[0]),'\\n',len(yf[0]))\nN = len(train[1][0])\nT = 1.0/N\n\nxf = rfftfreq(N, T)\n\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(20,10))\nplt.plot(xf[:100],np.abs(yf[0][:100]))\n\nplt.grid()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-22T17:12:35.668575Z","iopub.execute_input":"2021-08-22T17:12:35.668999Z","iopub.status.idle":"2021-08-22T17:12:35.793379Z","shell.execute_reply.started":"2021-08-22T17:12:35.668963Z","shell.execute_reply":"2021-08-22T17:12:35.791521Z"}}},{"cell_type":"markdown","source":"print('train tiene forma: ',train.shape)\n#train=np.transpose(train, (0,2,1))\ntrain.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-22T17:12:39.180897Z","iopub.execute_input":"2021-08-22T17:12:39.181383Z","iopub.status.idle":"2021-08-22T17:12:39.203537Z","shell.execute_reply.started":"2021-08-22T17:12:39.181339Z","shell.execute_reply":"2021-08-22T17:12:39.201285Z"}}},{"cell_type":"code","source":"#onehot_encoder = OneHotEncoder(sparse=False)\n#integer_encoded = y_labels.reshape(len(y_labels), 1)\n#y_labels = onehot_encoder.fit_transform(integer_encoded)\n#print(y_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# dividir en train/validation\n\n\nX_train, X_val, y_train, y_val = \\\n    train_test_split(train, y_labels, test_size=0.3, random_state=42)\n\nprint('X_train',X_train.shape,'y_train', y_train.shape,'\\nX_val',X_val.shape,'y_val',y_val.shape)\nver=X_train[0].shape\nprint(ver)","metadata":{"execution":{"iopub.status.busy":"2021-08-22T04:42:46.914015Z","iopub.execute_input":"2021-08-22T04:42:46.914337Z","iopub.status.idle":"2021-08-22T04:42:47.020726Z","shell.execute_reply.started":"2021-08-22T04:42:46.914303Z","shell.execute_reply":"2021-08-22T04:42:47.019746Z"}}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"\nX_trainT=torch.from_numpy(X_train)\ny_trainT=torch.from_numpy(y_train)\nX_valT=torch.from_numpy(X_val)\ny_valT=torch.from_numpy(y_val)\n\ntrain_dl = [[X_trainT,y_trainT]]\nval_dl = [[X_valT,y_valT]]\n\n","metadata":{"execution":{"iopub.status.busy":"2021-08-22T04:42:47.022014Z","iopub.execute_input":"2021-08-22T04:42:47.022312Z","iopub.status.idle":"2021-08-22T04:42:47.03524Z","shell.execute_reply.started":"2021-08-22T04:42:47.022271Z","shell.execute_reply":"2021-08-22T04:42:47.034067Z"}}},{"cell_type":"markdown","source":"y_trainT.type()\nX_trainT.type()","metadata":{"execution":{"iopub.status.busy":"2021-08-22T04:42:47.037028Z","iopub.execute_input":"2021-08-22T04:42:47.037479Z","iopub.status.idle":"2021-08-22T04:42:47.051672Z","shell.execute_reply.started":"2021-08-22T04:42:47.03743Z","shell.execute_reply":"2021-08-22T04:42:47.050822Z"}}},{"cell_type":"markdown","source":"# Definimos un Modelo","metadata":{}},{"cell_type":"code","source":"class funcionesBase(nn.Module):\n    \n    def training_step(self, batch,loss_):\n        graf, labels = batch \n        out = self(graf.to(device))\n        #print(out.shape,labels.shape)\n        #print(out)\n        loss = loss_(out.double().to(device), labels.double().to(device)) \n        return loss\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n        \n    def validation_step(self, batch, loss_):\n        graf, labels = batch \n        out = self(graf.double().to(device))  \n        #labels=labels.long()\n        loss = loss_(out.double().to(device), labels.double().to(device)) \n        acc = accuracy(out.to(device), labels.to(device))           \n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   \n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      \n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n\ndef accuracy(outputs, labels):\n    preds = torch.round(outputs)\n    return torch.tensor(torch.sum(preds == labels).item() / len(preds))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class clasificadorOndasGrav(funcionesBase):\n    \n    def __init__(self):\n        \n            super().__init__()   \n            self.c1=nn.Conv1d(in_channels=3, out_channels=64, kernel_size=15, stride=4).double()\n            self.m1=nn.MaxPool1d(4).double()\n            self.c2=nn.Conv1d(in_channels=64, out_channels=64, kernel_size=7, stride=2).double()\n            self.m2=nn.MaxPool1d(4).double()\n            self.c3=nn.Conv1d(in_channels=64, out_channels=64, kernel_size=7, stride=2).double()\n            self.m3=nn.MaxPool1d(2).double()\n            self.c4=nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, stride=1).double()\n            self.m4=nn.MaxPool1d(2).double()\n            self.f=nn.Flatten().double()\n            self.l1=nn.Linear(128,128).double()\n            self.r1=nn.ReLU().double()\n            self.l2=nn.Linear(128,50).double()\n            self.r2=nn.ReLU().double()\n            self.l3=nn.Linear(50,1).double()\n            self.s=nn.Sigmoid().double()\n            \n    \n    def forward(self, xb):\n        #self.network = self.network.double()\n        out=self.c1(xb.double())\n        out=self.m1(out)\n        out=self.c2(out)\n        out=self.m2(out)\n        out=self.c3(out)\n        out=self.m3(out)\n        out=self.c4(out)\n        out=self.m4(out)\n        print(out.shape)\n        out=self.f(out)\n        print(out.shape)\n        out=self.l1(out)\n        print(out.shape)\n        out=self.r1(out)\n        out=self.l2(out)\n        out=self.r2(out)\n        out=self.l3(out)\n        out=self.s(out)\n        return torch.squeeze(out)\n\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=clasificadorOndasGrav()\nmodel.to(device)\nmodel","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Para entrenar","metadata":{}},{"cell_type":"code","source":"@torch.no_grad()\ndef evaluate(model, loss_, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch, loss_) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, loss_, train_loader,val_loader, opt_func = torch.optim.SGD):\n    \n    history = []\n    optimizer = opt_func(model.parameters(),lr)\n    for epoch in range(epochs):\n        \n        model.train()\n        train_losses = []\n        for i,batch in enumerate(train_loader):\n        \n            loss = model.training_step(batch,loss_)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n            if i%10==0:\n                print(\".\",end=\"\")\n            if i%100==0:\n                print(\"\")\n                result = evaluate(model,loss_, val_loader)\n                result['train_loss'] = torch.stack(train_losses).mean().item()\n                model.epoch_end(epoch, result)\n                history.append(result)\n                model.train()\n    \n    return history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 3\nopt_func = torch.optim.Adam\nlr = 0.001\n\nloss=nn.BCELoss() \n\nhistory = fit(num_epochs, lr, model, loss, train_dl, val_dl, opt_func)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hacer predicción ","metadata":{}},{"cell_type":"code","source":"def hacer_predic (model,graf):\n    with torch.no_grad():\n        y_pred = model(graf)\n    return y_pred","metadata":{"execution":{"iopub.status.busy":"2021-08-25T22:54:25.894899Z","iopub.status.idle":"2021-08-25T22:54:25.895607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(\"../input/g2net-gravitational-wave-detection/sample_submission.csv\")\npred_list=[]\nfor i in range(1):\n    evento_a_pred = submission['id'].iloc[i]\n    path_pred = get_complete_path('../input/g2net-gravitational-wave-detection/test', evento_a_pred)\n    array = np.load(path_pred)\n    pred_list.append(array)\n    \ndata = torch.from_numpy(np.stack(pred_list, axis=0))\npred = hacer_predic(model,data)\npred.shape\n","metadata":{"execution":{"iopub.status.busy":"2021-08-25T22:54:25.89675Z","iopub.status.idle":"2021-08-25T22:54:25.897389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(\"../input/g2net-gravitational-wave-detection/sample_submission.csv\")\n\n\nsubmission.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T22:54:25.898733Z","iopub.status.idle":"2021-08-25T22:54:25.899353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(submission)","metadata":{"execution":{"iopub.status.busy":"2021-08-22T02:39:57.188643Z","iopub.status.idle":"2021-08-22T02:39:57.188968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}